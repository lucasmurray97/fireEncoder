{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBCyVYmb8OO7"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/aleju/imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qixUbenk8m3f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as D\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "import numpy as np\n",
    "\n",
    "class MiRuido:\n",
    "  def __init__(self):\n",
    "    self.aug = iaa.SaltAndPepper(0.1)\n",
    "\n",
    "  def __call__(self, img):\n",
    "    img = np.array(img)\n",
    "    return self.aug.augment_image(img)\n",
    "\n",
    "\n",
    "dataset_train = D.FashionMNIST('./dataset', download=True, train=True,\n",
    "                               transform=T.ToTensor())\n",
    "dataset_test = D.FashionMNIST('./dataset', download=True, train=False,\n",
    "                              transform = T.ToTensor())\n",
    "\n",
    "dataset_train_x = D.FashionMNIST('./dataset', download=False, train=True,\n",
    "                                transform=T.Compose([MiRuido(),T.ToTensor()]))\n",
    "dataset_test_x = D.FashionMNIST('./dataset', download=False, train=False,\n",
    "                               transform=T.Compose([MiRuido(), T.ToTensor()]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train,\n",
    "                                           batch_size=16, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test,\n",
    "                                           batch_size=16, shuffle=False)\n",
    "\n",
    "train_loader_x = torch.utils.data.DataLoader(dataset_train_x,\n",
    "                                           batch_size=16, shuffle=False)\n",
    "test_loader_x = torch.utils.data.DataLoader(dataset_test_x,\n",
    "                                           batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btZLdyxn_hKu"
   },
   "outputs": [],
   "source": [
    "#Inspeccion\n",
    "it1 = iter(train_loader)\n",
    "data1, target1 = next(it1)\n",
    "\n",
    "it2 = iter(train_loader_x)\n",
    "data2, target2 = next(it2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grid1 = torchvision.utils.make_grid(data1)\n",
    "plt.imshow(grid1.permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "grid2 = torchvision.utils.make_grid(data2)\n",
    "plt.imshow(grid2.permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WFPtKbGAAW8N"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mNoiseAutoencoder\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m(NoiseAutoencoder, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class NoiseAutoencoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(NoiseAutoencoder, self).__init__()\n",
    "\n",
    "    self.encoder = nn.Sequential(nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(2,2),\n",
    "                                nn.Conv2d(16, 32, kernel_size = 3, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(2, 2),\n",
    "                                nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(2, 2, padding=1))\n",
    "    self.decoder = nn.Sequential(nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Upsample(scale_factor=2),\n",
    "                                nn.Conv2d(16,32, kernel_size=3, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Upsample(scale_factor=2),\n",
    "                                nn.Conv2d(32, 64, kernel_size=3),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Upsample(scale_factor=2),\n",
    "                                nn.Conv2d(64, 1, kernel_size=3, padding=1))\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.decoder(self.encoder(x))\n",
    "\n",
    "\n",
    "net = NoiseAutoencoder()\n",
    "net = net.to('cuda')\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENyU8PvbD81W"
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "  for x,y in zip(train_loader, train_loader_x):\n",
    "    x = x[0]\n",
    "    y = y[0]\n",
    "\n",
    "    x = x.to('cuda')\n",
    "    y = y.to('cuda')\n",
    "\n",
    "    output = net(y)\n",
    "    loss = criterion(output, x)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Va-bESdFJee"
   },
   "outputs": [],
   "source": [
    "data1,_ = next(iter(test_loader))\n",
    "data2,_ = next(iter(test_loader_x))\n",
    "\n",
    "with torch.no_grad():\n",
    "  out = net(data2.to('cuda'))\n",
    "\n",
    "grid1 = torchvision.utils.make_grid(data1)\n",
    "plt.imshow(grid1.permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "grid2 = torchvision.utils.make_grid(data2)\n",
    "plt.imshow(grid2.permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "grid3 = torchvision.utils.make_grid(out.cpu())\n",
    "plt.imshow(grid3.permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mSTAsX0HNis"
   },
   "outputs": [],
   "source": [
    "!wget http://www.ivan-sipiran.com/downloads/noisy_docs_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XaMG-U9WMB81"
   },
   "outputs": [],
   "source": [
    "!unzip noisy_docs_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfUrzHqDMdRH"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('noisy_docs_data/train_cleaned/101.png')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6I2YWe_zNBRS"
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import glob\n",
    "\n",
    "class MiDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, root, tform=None, imgloader=PIL.Image.open):\n",
    "    super(MiDataset, self).__init__()\n",
    "\n",
    "    self.root = root\n",
    "    self.filenames = sorted(glob.glob(root + '/*.png'))\n",
    "    self.tform = tform\n",
    "    self.imgloader = imgloader\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.filenames)\n",
    "\n",
    "  def __getitem__(self, i):\n",
    "    out = self.imgloader(self.filenames[i])\n",
    "    if self.tform:\n",
    "      out = self.tform(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xohQ-od9Pizj"
   },
   "outputs": [],
   "source": [
    "doc_train_dataset = MiDataset(root='noisy_docs_data/train',\n",
    "                             tform=T.Compose([T.Resize((258, 540)),\n",
    "                                              T.ToTensor()]))\n",
    "\n",
    "doc_train_loader = torch.utils.data.DataLoader(doc_train_dataset,\n",
    "                                               batch_size=4)\n",
    "\n",
    "doc_target_dataset = MiDataset(root='noisy_docs_data/train_cleaned',\n",
    "                             tform=T.Compose([T.Resize((258, 540)),\n",
    "                                              T.ToTensor()]))\n",
    "\n",
    "doc_target_loader = torch.utils.data.DataLoader(doc_target_dataset,\n",
    "                                               batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8I96WDYQdDm"
   },
   "outputs": [],
   "source": [
    "class BackgroundRemoval(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(BackgroundRemoval, self).__init__()\n",
    "\n",
    "    self.encoder = nn.Sequential(\n",
    "        nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2))\n",
    "\n",
    "    self.decoder = nn.Sequential(\n",
    "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Upsample(scale_factor=2),\n",
    "        nn.Conv2d(64, 1, kernel_size=3, padding=1))\n",
    "\n",
    "  def forward(self,x):\n",
    "    return self.decoder(self.encoder(x))\n",
    "\n",
    "net2 = BackgroundRemoval()\n",
    "net2 = net2.to('cuda')\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net2.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "spR1HN5iZnIg"
   },
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "  for x,y in zip(doc_train_loader, doc_target_loader):\n",
    "    x = x.to('cuda')\n",
    "    y = y.to('cuda')\n",
    "\n",
    "    output = net2(x)\n",
    "    loss = criterion(output, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quiXSgW_Z6qk"
   },
   "outputs": [],
   "source": [
    "doc_test_dataset = MiDataset(root='noisy_docs_data/test',\n",
    "                             tform=T.Compose([T.Resize((258, 540)),\n",
    "                                              T.ToTensor()]))\n",
    "\n",
    "doc_test_loader = torch.utils.data.DataLoader(doc_test_dataset,\n",
    "                                               batch_size=4)\n",
    "\n",
    "data3 = next(iter(doc_test_loader))\n",
    "grid3 = torchvision.utils.make_grid(data3, nrow=1)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(grid3.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3i5ykpzccbh"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  out = net2(data3.to('cuda'))\n",
    "\n",
    "grid4 = torchvision.utils.make_grid(out.cpu(), nrow=1)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(grid4.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
